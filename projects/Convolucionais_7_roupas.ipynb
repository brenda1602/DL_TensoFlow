{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolucionais #7: roupas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11jAYbIfVo5Jki0xkninO99rWifQCjDFG",
      "authorship_tag": "ABX9TyOSjkQ+ERdKVOqf9bTjhk4/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brenda1602/DL_TensorFlow/blob/master/Convolucionais_7_roupas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Rri6pb5_Oo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "692d22ce-e977-44e0-de36-31099d59bcac"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "import random\n",
        "tf.__version__\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1bbpAWLCuon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_train_df=pd.read_csv('/content/drive/My Drive/fashion-mnist-train.csv', sep= ',')\n",
        "fashion_test_df=pd.read_csv('/content/drive/My Drive/fashion-mnist-test.csv', sep= ',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XijV9_eEEhXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training=np.array(fashion_train_df,dtype= 'float32')\n",
        "testing=np.array(fashion_test_df,dtype= 'float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqB-77vkIb2-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5dede7a-9e0d-4a63-e7fd-ff90108ae427"
      },
      "source": [
        "training.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 785)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfCNd1fGJRcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "51fa1fd5-7e01-4b3e-b2d9-b41ef2723643"
      },
      "source": [
        "i= random.randint(1,60000)\n",
        "plt.imshow(training[i,1:].reshape(28,28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f84fe186908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yAblllkLcNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc27a8d5-96f9-47ac-c4b2-fe71ccfa058c"
      },
      "source": [
        "label=training[i,0]\n",
        "label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry_CsbqjQV0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=training[:,1:]/255\n",
        "y_train=training[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfDcDrK-RPk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test=testing[:,1:]/255\n",
        "y_test=testing[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xit518l6SaBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1516675e-2852-4ec3-e5cc-221172b4dda9"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcbattMmRbCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=x_train.reshape(x_train.shape[0],*(28,28,1))\n",
        "x_test=x_test.reshape(x_test.shape[0],*(28,28,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp-UCan0UxyQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8eabf5c-8248-481b-cba9-196e796c5ec2"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49RX-KSaU448",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6681e6f5-d58d-4b34-ca24-c5544eda9f9d"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eiz3Qsb5Vuwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "9342b078-23b2-4a87-90b0-e18e41a6873b"
      },
      "source": [
        "from tensorflow.keras import layers,models\n",
        "cnn = models.Sequential()\n",
        "\n",
        "cnn.add(layers.Conv2D(32,(3,3),activation='relu', input_shape=(28,28,1)))\n",
        "cnn.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "cnn.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "cnn.add(layers.MaxPooling2D(2,2))\n",
        "\n",
        "cnn.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "\n",
        "cnn.add(layers.Flatten())\n",
        "\n",
        "cnn.add(layers.Dense(64,activation='relu'))\n",
        "\n",
        "cnn.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JrnWjObgqHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.compile(loss='sparse_categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMMCIo1NkpB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enamTZ53hRdn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f4e12de-33ce-49a3-cfbd-fd79716394b1"
      },
      "source": [
        "epochs=150\n",
        "history=cnn.fit(x_train,y_train,batch_size=512,epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "118/118 [==============================] - 43s 363ms/step - loss: 0.8822 - accuracy: 0.6809\n",
            "Epoch 2/150\n",
            "118/118 [==============================] - 43s 367ms/step - loss: 0.5057 - accuracy: 0.8143\n",
            "Epoch 3/150\n",
            "118/118 [==============================] - 44s 370ms/step - loss: 0.4210 - accuracy: 0.8488\n",
            "Epoch 4/150\n",
            "118/118 [==============================] - 43s 366ms/step - loss: 0.3777 - accuracy: 0.8630\n",
            "Epoch 5/150\n",
            "118/118 [==============================] - 43s 365ms/step - loss: 0.3490 - accuracy: 0.8744\n",
            "Epoch 6/150\n",
            "118/118 [==============================] - 43s 366ms/step - loss: 0.3227 - accuracy: 0.8848\n",
            "Epoch 7/150\n",
            "118/118 [==============================] - 43s 364ms/step - loss: 0.3140 - accuracy: 0.8875\n",
            "Epoch 8/150\n",
            "118/118 [==============================] - 46s 391ms/step - loss: 0.2934 - accuracy: 0.8948\n",
            "Epoch 9/150\n",
            "118/118 [==============================] - 43s 365ms/step - loss: 0.2805 - accuracy: 0.8995\n",
            "Epoch 10/150\n",
            "118/118 [==============================] - 43s 362ms/step - loss: 0.2724 - accuracy: 0.9020\n",
            "Epoch 11/150\n",
            "118/118 [==============================] - 42s 360ms/step - loss: 0.2637 - accuracy: 0.9049\n",
            "Epoch 12/150\n",
            "118/118 [==============================] - 43s 363ms/step - loss: 0.2547 - accuracy: 0.9082\n",
            "Epoch 13/150\n",
            "118/118 [==============================] - 42s 360ms/step - loss: 0.2447 - accuracy: 0.9128\n",
            "Epoch 14/150\n",
            "118/118 [==============================] - 42s 360ms/step - loss: 0.2354 - accuracy: 0.9145\n",
            "Epoch 15/150\n",
            "118/118 [==============================] - 43s 362ms/step - loss: 0.2321 - accuracy: 0.9155\n",
            "Epoch 16/150\n",
            "118/118 [==============================] - 43s 361ms/step - loss: 0.2232 - accuracy: 0.9191\n",
            "Epoch 17/150\n",
            "118/118 [==============================] - 43s 364ms/step - loss: 0.2172 - accuracy: 0.9223\n",
            "Epoch 18/150\n",
            "118/118 [==============================] - 43s 362ms/step - loss: 0.2084 - accuracy: 0.9248\n",
            "Epoch 19/150\n",
            "118/118 [==============================] - 43s 361ms/step - loss: 0.2012 - accuracy: 0.9279\n",
            "Epoch 20/150\n",
            "118/118 [==============================] - 43s 360ms/step - loss: 0.1981 - accuracy: 0.9284\n",
            "Epoch 21/150\n",
            "118/118 [==============================] - 43s 361ms/step - loss: 0.1885 - accuracy: 0.9325\n",
            "Epoch 22/150\n",
            "118/118 [==============================] - 46s 389ms/step - loss: 0.1846 - accuracy: 0.9338\n",
            "Epoch 23/150\n",
            "118/118 [==============================] - 43s 362ms/step - loss: 0.1799 - accuracy: 0.9344\n",
            "Epoch 24/150\n",
            "118/118 [==============================] - 43s 365ms/step - loss: 0.1777 - accuracy: 0.9356\n",
            "Epoch 25/150\n",
            "118/118 [==============================] - 42s 359ms/step - loss: 0.1693 - accuracy: 0.9386\n",
            "Epoch 26/150\n",
            "118/118 [==============================] - 42s 359ms/step - loss: 0.1625 - accuracy: 0.9412\n",
            "Epoch 27/150\n",
            "118/118 [==============================] - 42s 356ms/step - loss: 0.1592 - accuracy: 0.9419\n",
            "Epoch 28/150\n",
            "118/118 [==============================] - 42s 356ms/step - loss: 0.1529 - accuracy: 0.9445\n",
            "Epoch 29/150\n",
            "118/118 [==============================] - 42s 360ms/step - loss: 0.1495 - accuracy: 0.9462\n",
            "Epoch 30/150\n",
            "118/118 [==============================] - 42s 358ms/step - loss: 0.1426 - accuracy: 0.9485\n",
            "Epoch 31/150\n",
            "118/118 [==============================] - 43s 363ms/step - loss: 0.1401 - accuracy: 0.9488\n",
            "Epoch 32/150\n",
            "118/118 [==============================] - 42s 357ms/step - loss: 0.1316 - accuracy: 0.9516\n",
            "Epoch 33/150\n",
            "118/118 [==============================] - 41s 351ms/step - loss: 0.1327 - accuracy: 0.9516\n",
            "Epoch 34/150\n",
            "118/118 [==============================] - 42s 356ms/step - loss: 0.1242 - accuracy: 0.9544\n",
            "Epoch 35/150\n",
            "118/118 [==============================] - 42s 358ms/step - loss: 0.1189 - accuracy: 0.9572\n",
            "Epoch 36/150\n",
            "118/118 [==============================] - 42s 355ms/step - loss: 0.1173 - accuracy: 0.9573\n",
            "Epoch 37/150\n",
            "118/118 [==============================] - 45s 380ms/step - loss: 0.1120 - accuracy: 0.9589\n",
            "Epoch 38/150\n",
            "118/118 [==============================] - 42s 352ms/step - loss: 0.1082 - accuracy: 0.9611\n",
            "Epoch 39/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.1092 - accuracy: 0.9600\n",
            "Epoch 40/150\n",
            "118/118 [==============================] - 42s 355ms/step - loss: 0.1003 - accuracy: 0.9643\n",
            "Epoch 41/150\n",
            "118/118 [==============================] - 42s 359ms/step - loss: 0.0972 - accuracy: 0.9643\n",
            "Epoch 42/150\n",
            "118/118 [==============================] - 42s 356ms/step - loss: 0.0920 - accuracy: 0.9675\n",
            "Epoch 43/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.0857 - accuracy: 0.9695\n",
            "Epoch 44/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.0827 - accuracy: 0.9704\n",
            "Epoch 45/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.0804 - accuracy: 0.9713\n",
            "Epoch 46/150\n",
            "118/118 [==============================] - 41s 351ms/step - loss: 0.0784 - accuracy: 0.9720\n",
            "Epoch 47/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.0754 - accuracy: 0.9724\n",
            "Epoch 48/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0764 - accuracy: 0.9728\n",
            "Epoch 49/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 0.0675 - accuracy: 0.9763\n",
            "Epoch 50/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 0.0652 - accuracy: 0.9772\n",
            "Epoch 51/150\n",
            "118/118 [==============================] - 44s 374ms/step - loss: 0.0671 - accuracy: 0.9760\n",
            "Epoch 52/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 0.0584 - accuracy: 0.9796\n",
            "Epoch 53/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.0621 - accuracy: 0.9780\n",
            "Epoch 54/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0572 - accuracy: 0.9793\n",
            "Epoch 55/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0557 - accuracy: 0.9803\n",
            "Epoch 56/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0514 - accuracy: 0.9822\n",
            "Epoch 57/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0443 - accuracy: 0.9849\n",
            "Epoch 58/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0497 - accuracy: 0.9827\n",
            "Epoch 59/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0394 - accuracy: 0.9869\n",
            "Epoch 60/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0397 - accuracy: 0.9863\n",
            "Epoch 61/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0392 - accuracy: 0.9869\n",
            "Epoch 62/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0407 - accuracy: 0.9858\n",
            "Epoch 63/150\n",
            "118/118 [==============================] - 42s 356ms/step - loss: 0.0352 - accuracy: 0.9876\n",
            "Epoch 64/150\n",
            "118/118 [==============================] - 41s 351ms/step - loss: 0.0332 - accuracy: 0.9887\n",
            "Epoch 65/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.0359 - accuracy: 0.9878\n",
            "Epoch 66/150\n",
            "118/118 [==============================] - 44s 374ms/step - loss: 0.0302 - accuracy: 0.9901\n",
            "Epoch 67/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0355 - accuracy: 0.9869\n",
            "Epoch 68/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.0308 - accuracy: 0.9894\n",
            "Epoch 69/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0245 - accuracy: 0.9920\n",
            "Epoch 70/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.0283 - accuracy: 0.9905\n",
            "Epoch 71/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0296 - accuracy: 0.9894\n",
            "Epoch 72/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0219 - accuracy: 0.9930\n",
            "Epoch 73/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0202 - accuracy: 0.9934\n",
            "Epoch 74/150\n",
            "118/118 [==============================] - 41s 350ms/step - loss: 0.0185 - accuracy: 0.9941\n",
            "Epoch 75/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0153 - accuracy: 0.9960\n",
            "Epoch 76/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.0442 - accuracy: 0.9837\n",
            "Epoch 77/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.0272 - accuracy: 0.9901\n",
            "Epoch 78/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0190 - accuracy: 0.9939\n",
            "Epoch 79/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0125 - accuracy: 0.9964\n",
            "Epoch 80/150\n",
            "118/118 [==============================] - 44s 374ms/step - loss: 0.0181 - accuracy: 0.9942\n",
            "Epoch 81/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0129 - accuracy: 0.9964\n",
            "Epoch 82/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0204 - accuracy: 0.9933\n",
            "Epoch 83/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0263 - accuracy: 0.9904\n",
            "Epoch 84/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0227 - accuracy: 0.9920\n",
            "Epoch 85/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0113 - accuracy: 0.9966\n",
            "Epoch 86/150\n",
            "118/118 [==============================] - 40s 342ms/step - loss: 0.0107 - accuracy: 0.9969\n",
            "Epoch 87/150\n",
            "118/118 [==============================] - 43s 366ms/step - loss: 0.0300 - accuracy: 0.9891\n",
            "Epoch 88/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0186 - accuracy: 0.9936\n",
            "Epoch 89/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0247 - accuracy: 0.9913\n",
            "Epoch 90/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0206 - accuracy: 0.9927\n",
            "Epoch 91/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0083 - accuracy: 0.9978\n",
            "Epoch 92/150\n",
            "118/118 [==============================] - 43s 360ms/step - loss: 0.0043 - accuracy: 0.9993\n",
            "Epoch 93/150\n",
            "118/118 [==============================] - 41s 350ms/step - loss: 0.0033 - accuracy: 0.9996\n",
            "Epoch 94/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.0026 - accuracy: 0.9998\n",
            "Epoch 95/150\n",
            "118/118 [==============================] - 44s 375ms/step - loss: 0.0016 - accuracy: 0.9999\n",
            "Epoch 96/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 97/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 98/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 99/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 100/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 8.3599e-04 - accuracy: 1.0000\n",
            "Epoch 101/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 7.4402e-04 - accuracy: 1.0000\n",
            "Epoch 102/150\n",
            "118/118 [==============================] - 41s 349ms/step - loss: 6.9591e-04 - accuracy: 1.0000\n",
            "Epoch 103/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0851 - accuracy: 0.9749\n",
            "Epoch 104/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0688 - accuracy: 0.9764\n",
            "Epoch 105/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 0.0356 - accuracy: 0.9872\n",
            "Epoch 106/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 0.0176 - accuracy: 0.9936\n",
            "Epoch 107/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 0.0064 - accuracy: 0.9986\n",
            "Epoch 108/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 0.0030 - accuracy: 0.9998\n",
            "Epoch 109/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 0.0024 - accuracy: 0.9999\n",
            "Epoch 110/150\n",
            "118/118 [==============================] - 44s 372ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 111/150\n",
            "118/118 [==============================] - 41s 345ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 112/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 113/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 114/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 8.5352e-04 - accuracy: 1.0000\n",
            "Epoch 115/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 7.3919e-04 - accuracy: 1.0000\n",
            "Epoch 116/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 6.3158e-04 - accuracy: 1.0000\n",
            "Epoch 117/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 5.7613e-04 - accuracy: 1.0000\n",
            "Epoch 118/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 5.2834e-04 - accuracy: 1.0000\n",
            "Epoch 119/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 5.0531e-04 - accuracy: 1.0000\n",
            "Epoch 120/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 4.5210e-04 - accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 4.3108e-04 - accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 4.0302e-04 - accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 3.6969e-04 - accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "118/118 [==============================] - 44s 376ms/step - loss: 3.5691e-04 - accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 3.2408e-04 - accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 3.1312e-04 - accuracy: 1.0000\n",
            "Epoch 127/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 2.8934e-04 - accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 2.6954e-04 - accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 2.5800e-04 - accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 2.3497e-04 - accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 2.2118e-04 - accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 2.2466e-04 - accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 1.9715e-04 - accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 1.8337e-04 - accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 1.7164e-04 - accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 1.6247e-04 - accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 1.4923e-04 - accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 1.4228e-04 - accuracy: 1.0000\n",
            "Epoch 139/150\n",
            "118/118 [==============================] - 44s 373ms/step - loss: 1.3725e-04 - accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 1.4231e-04 - accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "118/118 [==============================] - 41s 344ms/step - loss: 0.1746 - accuracy: 0.9491\n",
            "Epoch 142/150\n",
            "118/118 [==============================] - 41s 344ms/step - loss: 0.0777 - accuracy: 0.9719\n",
            "Epoch 143/150\n",
            "118/118 [==============================] - 41s 345ms/step - loss: 0.0352 - accuracy: 0.9869\n",
            "Epoch 144/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0210 - accuracy: 0.9927\n",
            "Epoch 145/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0137 - accuracy: 0.9952\n",
            "Epoch 146/150\n",
            "118/118 [==============================] - 41s 346ms/step - loss: 0.0052 - accuracy: 0.9987\n",
            "Epoch 147/150\n",
            "118/118 [==============================] - 41s 347ms/step - loss: 0.0051 - accuracy: 0.9988\n",
            "Epoch 148/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0031 - accuracy: 0.9994\n",
            "Epoch 149/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "118/118 [==============================] - 41s 348ms/step - loss: 6.2880e-04 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxYr43imJXOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}